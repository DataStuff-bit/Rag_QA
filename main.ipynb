{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "545b788f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Main RAG pipeline example with Gemini LLM\"\"\"\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "\n",
    "from src.rag.document_processing import DocumentProcessor\n",
    "from src.rag.vector_store import VectorStoreFactory\n",
    "from src.rag.retrieval import HybridRetriever\n",
    "from src.rag.generation import RAGGenerator\n",
    "from src.rag.generation.prompts import GroundingPrompts\n",
    "\n",
    "\n",
    "def setup_embedding_fn():\n",
    "    \"\"\"Setup embedding function using Gemini\"\"\"\n",
    "    def embed_text(text: str):\n",
    "        \"\"\"Embed text using Gemini's embedding model\"\"\"\n",
    "        try:\n",
    "            result = genai.embed_content(\n",
    "                model=\"models/gemini-embedding-001\",\n",
    "                content=text,\n",
    "            )\n",
    "            return result['embedding']\n",
    "        except Exception as e:\n",
    "            print(f\"Embedding failed: {e}\")\n",
    "            # Return a dummy embedding on failure\n",
    "            return [0.0] * 768\n",
    "    \n",
    "    return embed_text\n",
    "\n",
    "\n",
    "def setup_llm_fn():\n",
    "    \"\"\"Setup LLM function using Gemini\"\"\"\n",
    "    system_instruction = GroundingPrompts.system_prompt()\n",
    "    model = genai.GenerativeModel(\n",
    "        \"models/gemini-2.5-flash\",\n",
    "        system_instruction=system_instruction\n",
    "    )\n",
    "    \n",
    "    def generate_response(prompt: str) -> str:\n",
    "        \"\"\"Generate response using Gemini\"\"\"\n",
    "        try:\n",
    "            response = model.generate_content(prompt)\n",
    "            return response.text\n",
    "        except Exception as e:\n",
    "            return f\"Error generating response: {e}\"\n",
    "    \n",
    "    return generate_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff8ce85f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AIzaSyChhGHIp9KrO-Z1tKQZNr6KL9dV0jes_i0'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "218314a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python-dotenv could not parse statement starting at line 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RAG System for Product Documentation QA\n",
      "================================================================================\n",
      "\n",
      "[1] DOCUMENT PROCESSING\n",
      "--------------------------------------------------------------------------------\n",
      "✓ Loaded 4 documents\n",
      "  - multi_passage_answer_questions.csv (12354 chars)\n",
      "  - coffee_maker_faq.txt (1597 chars)\n",
      "  - single_passage_answer_questions.csv (8921 chars)\n",
      "  - smart_coffee_maker_manual.txt (1567 chars)\n",
      "✓ Created 12 chunks\n",
      "  Total tokens: 4909\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"Main RAG pipeline demonstration\"\"\"\n",
    "\n",
    "# Load environment\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"GOOGLE_API_KEY not set. Please configure .env file.\")\n",
    "\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"RAG System for Product Documentation QA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Step 1: Load and process documents\n",
    "print(\"\\n[1] DOCUMENT PROCESSING\")\n",
    "print(\"-\" * 80)\n",
    "processor = DocumentProcessor(chunk_size=400, chunk_overlap=100)\n",
    "\n",
    "docs = processor.load_documents(\"data/\")\n",
    "print(f\"✓ Loaded {len(docs)} documents\")\n",
    "for doc in docs:\n",
    "    print(f\"  - {doc.filename} ({len(doc.content)} chars)\")\n",
    "\n",
    "chunks = processor.process()\n",
    "print(f\"✓ Created {len(chunks)} chunks\")\n",
    "print(f\"  Total tokens: {sum(c.token_count for c in chunks)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0a83ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunks[0].content  # For inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64f53ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2] VECTOR STORE SETUP\n",
      "--------------------------------------------------------------------------------\n",
      "✓ Created in-memory vector store\n",
      "✓ Setup Gemini embedding function\n",
      "Embedding and storing chunks...\n",
      "  Progress: 0/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1767886522.391837 4923762 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 3/12\n",
      "  Progress: 6/12\n",
      "  Progress: 9/12\n",
      "✓ Vector store ready: {'total_chunks': 12, 'chunks_with_embeddings': 12, 'total_tokens': 4909}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 2: Setup vector store\n",
    "print(\"\\n[2] VECTOR STORE SETUP\")\n",
    "print(\"-\" * 80)\n",
    "vector_store = VectorStoreFactory.create(\"in_memory\")\n",
    "print(\"✓ Created in-memory vector store\")\n",
    "\n",
    "# Setup embedding function\n",
    "embedding_fn = setup_embedding_fn()\n",
    "print(\"✓ Setup Gemini embedding function\")\n",
    "\n",
    "# Embed and store chunks\n",
    "print(\"Embedding and storing chunks...\")\n",
    "for i, chunk in enumerate(chunks):\n",
    "    if i % max(1, len(chunks) // 4) == 0:\n",
    "        print(f\"  Progress: {i}/{len(chunks)}\")\n",
    "    try:\n",
    "        embedding = embedding_fn(chunk.content)\n",
    "        chunk.embedding = embedding\n",
    "    except Exception as e:\n",
    "        print(f\"Embedding failed for chunk {chunk.chunk_id}: {e}\")\n",
    "\n",
    "vector_store.add_chunks(chunks)\n",
    "stats = vector_store.get_stats()\n",
    "print(f\"✓ Vector store ready: {stats}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ed82a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3] RETRIEVAL SETUP\n",
      "--------------------------------------------------------------------------------\n",
      "✓ Hybrid retriever configured (60% dense, 40% sparse)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 3: Setup retrieval\n",
    "print(\"\\n[3] RETRIEVAL SETUP\")\n",
    "print(\"-\" * 80)\n",
    "retriever = HybridRetriever(\n",
    "    vector_store=vector_store,\n",
    "    embedding_fn=embedding_fn,\n",
    "    dense_weight=0.6,\n",
    "    sparse_weight=0.4,\n",
    ")\n",
    "print(\"✓ Hybrid retriever configured (60% dense, 40% sparse)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "608b9a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[4] GENERATION SETUP\n",
      "--------------------------------------------------------------------------------\n",
      "✓ Gemini LLM configured\n",
      "✓ RAG generator ready\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 4: Setup generation\n",
    "print(\"\\n[4] GENERATION SETUP\")\n",
    "print(\"-\" * 80)\n",
    "llm_fn = setup_llm_fn()\n",
    "print(\"✓ Gemini LLM configured\")\n",
    "\n",
    "generator = RAGGenerator(\n",
    "    retriever=retriever,\n",
    "    llm_fn=llm_fn,\n",
    "    min_context_score=0.2,\n",
    "    top_k=5,\n",
    ")\n",
    "print(\"✓ RAG generator ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dce61d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33746452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[5] EXAMPLE QUERIES\n",
      "================================================================================\n",
      "\n",
      "Query 1: How do I troubleshoot WiFi connection issues?\n",
      "--------------------------------------------------------------------------------\n",
      "Answer: To troubleshoot WiFi connection issues, you can follow these steps:\n",
      "\n",
      "*   **If your phone can't find the device in the app:**\n",
      "    1.  Ensure the device is powered on.\n",
      "    2.  Make sure your phone is on the same WiFi network as the device.\n",
      "    3.  Go to app Settings > Forget Device > Re-add Device.\n",
      "    4.  Enter your WiFi credentials when prompted.\n",
      "    [Source: coffee_maker_faq.txt]\n",
      "\n",
      "*   **If the WiFi connection fails:**\n",
      "    1.  Restart the device (unplug for 30 seconds).\n",
      "    2.  Ensure a 2.4GHz W...\n",
      "Sources: single_passage_answer_questions.csv, coffee_maker_faq.txt, smart_coffee_maker_manual.txt\n",
      "Confidence: 0.48\n",
      "Retrieved 5 context chunks\n",
      "Chunk scores:\n",
      "  - coffee_maker_faq_chunk_0: 0.499\n",
      "  - smart_coffee_maker_manual_chunk_0: 0.497\n",
      "  - single_passage_answer_questions_chunk_2: 0.467\n",
      "\n",
      "================================================================================\n",
      "RAG Pipeline demonstration complete!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 5: Run example queries\n",
    "print(\"\\n[5] EXAMPLE QUERIES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "queries = [\n",
    "    \"How do I troubleshoot WiFi connection issues?\",\n",
    "    # \"What is the recommended water temperature for brewing?\",\n",
    "    # \"Can multiple phones control the same coffee maker?\",\n",
    "    # \"How often should I clean the machine?\",\n",
    "]\n",
    "\n",
    "for i, query in enumerate(queries, 1):\n",
    "    print(f\"\\nQuery {i}: {query}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    response = generator.generate(query, use_verification=False)\n",
    "    \n",
    "    print(f\"Answer: {response['answer'][:500]}...\")\n",
    "    print(f\"Sources: {', '.join(response['sources'])}\")\n",
    "    print(f\"Confidence: {response['confidence']:.2f}\")\n",
    "    print(f\"Retrieved {response['num_context_chunks']} context chunks\")\n",
    "    \n",
    "    if response['chunk_scores']:\n",
    "        print(\"Chunk scores:\")\n",
    "        for score in response['chunk_scores'][:3]:\n",
    "            print(f\"  - {score['chunk_id']}: {score['score']:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RAG Pipeline demonstration complete!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "954392e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What was at the pintxo bars?\"\n",
    "response = generator.generate(query, use_verification=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "154b93c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'You drank txakoli at the pintxo bars. [Source: single_passage_answer_questions.csv]',\n",
       " 'sources': ['single_passage_answer_questions.csv',\n",
       "  'multi_passage_answer_questions.csv'],\n",
       " 'confidence': 0.487216517352291,\n",
       " 'grounded': True,\n",
       " 'retrieval_reasoning': {'query': 'What was at the pintxo bars?',\n",
       "  'retrieval_method': 'hybrid',\n",
       "  'top_k_requested': 5,\n",
       "  'results_count': 5,\n",
       "  'weights': {'dense': 0.6, 'sparse': 0.4}},\n",
       " 'num_context_chunks': 5,\n",
       " 'verification': None,\n",
       " 'chunk_scores': [{'chunk_id': 'single_passage_answer_questions_chunk_2',\n",
       "   'score': 0.5085634186199635},\n",
       "  {'chunk_id': 'multi_passage_answer_questions_chunk_2',\n",
       "   'score': 0.4887008096149143},\n",
       "  {'chunk_id': 'single_passage_answer_questions_chunk_1',\n",
       "   'score': 0.4833993764042124},\n",
       "  {'chunk_id': 'multi_passage_answer_questions_chunk_0',\n",
       "   'score': 0.4780575240894486},\n",
       "  {'chunk_id': 'multi_passage_answer_questions_chunk_1',\n",
       "   'score': 0.4773614580329162}]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40885894",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
